### M√°y h·ªçc n√¢ng cao 

- ML: manual feature engineering; DL: automated feature engineering
- DL kh√¥ng ph·∫£i c√†ng "deep" l√† c√†ng t·ªët
- DL kh√¥ng ph·∫£i l√† ƒë·ª•ng c√°i g√¨ c≈©ng th·ª≠, m√† ph·∫£i coi xem l√† n√≥ c√≥ ƒë√°ng ƒë·ªÉ th·ª≠ kh√¥ng?
- Kh√¥ng ch·∫°y GridSearchCV trong DL
- Normalize c·∫£ t·∫≠p train v√† t·∫≠p test s·∫Ω d·∫´n t·ªõi Data leakage
- T·∫≠p validation d√πng ƒë·ªÉ: Early stopping, t√¨m hyperparameters
    - Nh∆∞ng t·∫≠p test v·∫´n l√†m ƒë∆∞·ª£c
- Ph√¢n bi·ªát gi·ªØa validation vs test: validation l√† t·∫≠p th·ª≠ ƒë·ªÉ ngƒÉn model kh√¥ng b·ªã overfit theo c√°ch train, tr√™n t·∫≠p test
- So s√°nh models d·ª±a tr√™n:
    - ƒë·ªô ch√≠nh x√°c
    - s·ªë l∆∞·ª£ng parameters
    - chi ph√≠ t√≠nh to√°n
- Gi·ªõi h·∫°n c·ªßa Fully Connected Layer?
    - ƒë·ªëi v·ªõi 2D data, c·∫ßn flatten -> l√†m m·∫•t th√¥ng tin
    - t·ªën nhi·ªÅu parameters
- Batch Normalization s·ª≠ d·ª•ng ƒë·ªÉ tr√°nh exploding gradient v√† vanishing gradient
- Khi n√†o n√™n d√πng Pooling layer thay v√¨ Conv layer? (∆∞u ƒëi·ªÉm c·ªßa Pooling)
    - Tr√°nh d√πng ·ªü g·∫ßn input do s·∫Ω m·∫•t m√°t th√¥ng tin
    - Kh√¥ng c√≥ learnable parameter -> model nh·∫π h∆°n
    - Nhanh h∆°n -> m·∫•t th√¥ng tin
- T·∫°i sao Max Pooling l·∫°i ƒë∆∞·ª£c d√πng nhi·ªÅu?
    - Do l·ªãch s·ª≠ üôÇ
- Data >>>>>> model
- Data sai -> Model sai. B·∫£n ch·∫•t c·ªßa model l√† h·ªçc thu·ªôc l√≤ng data
- Model t·ªët != Model c√≥ th·ªÉ s·ª≠ d·ª•ng ƒë∆∞·ª£c
- Batch size nh∆∞ n√†o l√† t·ªëi ∆∞u?
    - Batch size l·ªõn nh·∫•t m√°y c√≥ th·ªÉ train
- T·∫°i sao ML kh√¥ng c·∫ßn batch m√† DL l·∫°i c·∫ßn?
    - Data c·ªßa ML kh√¥ng qu√° to, n·∫øu to th√¨ ML ch·ªâ c√≥ 1 c√°i minium
- T·∫°i sao batch l·ªõn l·∫°i t·ªët h∆°n batch nh·ªè?
    - Statistics c·ªßa batch l·ªõn g·∫ßn v·ªõi dataset h∆°n
- Nh√¨n v√¥ Loss ƒë·ªÉ ƒëi·ªÅu ch·ªânh learning rate
- Optimizer: Adam = Momentum + AdaGrad + RMSProp

Others:
- Y·∫øu t·ªë quan tr·ªçng nh·∫•t (?) trong v·∫•n ƒë·ªÅ ngh·ªâ vi·ªác: m·ªëi quan h·ªá v·ªõi s·∫øp
- M·ªôt s·ªë c√¢u h·ªèi m√¨nh note ƒë∆∞·ª£c ~~nh∆∞ng m√¨nh qu√™n ghi c√¢u tr·∫£ l·ªùi~~:
    - S·ªë l∆∞·ª£ng Convolutional layers t·ªëi ∆∞u cho CNN?
    - T·∫°i sao Dropout c√≥ th·ªÉ tr√°nh overfitting?
    - Model h·ªôi t·ª• th√¨ c√≥ d√πng ƒë∆∞·ª£c kh√¥ng?
    - Khi n√†o d√πng lo·∫°i Pooling n√†o?